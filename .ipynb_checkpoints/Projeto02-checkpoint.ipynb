{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 13/Set at√© √†s 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "At√© o dia 06 de Setembro √†s 23:59, o notebook e o xlsx devem estar no Github com as seguintes evid√™ncias: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste j√° classificado.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conex√£o com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que ser√£o utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados √© necess√°rio ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@CuryIzidoro***\n",
    "\n",
    "\n",
    "1. Caso ainda n√£o tenha uma: https://twitter.com/signup\n",
    "1. Depois √© necess√°rio registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote tamb√©m:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATEN√á√ÉO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele cont√©m as chaves necess√°rias para realizar as opera√ß√µes no twitter de forma autom√°tica e portanto √© equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as opera√ß√µes manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo n√£o precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, n√£o haver√° uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Kit Kat'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "#i = 1\n",
    "#msgs = []\n",
    "#for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    " #   msgs.append(msg.text.lower())\n",
    "  #  i += 1\n",
    "   # if i > n:\n",
    "    #    break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "#shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinamento = pd.read_excel('Kit Kat.xlsx')\n",
    "teste = pd.read_excel('Kit Kat.xlsx', sheetname = 'Teste')\n",
    "\n",
    "#listas\n",
    "Ltreinamento = []\n",
    "Lteste = []\n",
    "classificacao_Teste = []\n",
    "classificacao_Treinamento = []\n",
    "tweet_relevante = []\n",
    "tweet_irrelevante = []\n",
    "tipo_de_amostra = 1\n",
    "quantidade_de_palavras = [0,0,0]\n",
    "\n",
    "lista_freq_de_palavras= [[\"Kit Kat\",0,0]]\n",
    "\n",
    "#percorre o dataframe e o transforma em lista\n",
    "\n",
    "for i in range (0,t):\n",
    "    Ltreinamento.append([treinamento[\"Treinamento\"][i],treinamento[\"Classificacao\"][i]])\n",
    "    \n",
    "for i in range (0,t):\n",
    "    classificacao_Treinamento.append(treinamento[\"Classificacao\"][i])\n",
    "    \n",
    "for i in range (0,(n-t)):\n",
    "    Lteste.append([teste[\"Teste\"][i],teste[\"Classificacao\"][i]])\n",
    "\n",
    "for i in range (0,(n-t)):\n",
    "    classificacao_Teste.append(teste[\"Classificacao\"][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora voc√™ deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem √© relevante ou n√£o.<br /> \n",
    "N√£o se esque√ßa de colocar um nome para a coluna na c√©lula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu c√≥digo abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiply(n):\n",
    "    total = 1\n",
    "    for i in range(0, len(n)):\n",
    "        total *= n[i]\n",
    "    return total\n",
    "\n",
    "class Classificador:\n",
    "    \n",
    "    def __init__(self,Ltreinamento,Lteste):\n",
    "        \n",
    "        self.Ltreinamento = Ltreinamento\n",
    "        self.Lteste = Lteste\n",
    "        self.lista_freq_de_palavras = lista_freq_de_palavras\n",
    "        self.tweet_relevante = tweet_relevante\n",
    "        self.tweet_irrelevante = tweet_irrelevante\n",
    "        self.tipo_de_amostra = tipo_de_amostra\n",
    "        self.quantidade_de_palavras = quantidade_de_palavras\n",
    "        \n",
    "    def normalize(self,Num):\n",
    "        if (Num == 0): \n",
    "            lista = self.Ltreinamento\n",
    "        else:\n",
    "            lista = self.Lteste\n",
    "        for tweet in lista:\n",
    "            tweet[0] = tweet[0].replace(\",\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"$\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"+\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"-\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"=\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"%\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"*\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"/\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"/n\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\":\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"(\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\")\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"~\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"[\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"]\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\".\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\";\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"_\",\" \")\n",
    "            tweet[0] = tweet[0].replace(\"  \",\" \")\n",
    "        if (Num == 0): \n",
    "            self.Ltreinamento = lista\n",
    "        else:\n",
    "            self.Lteste =  lista\n",
    "            \n",
    "            \n",
    "    def treino(self):\n",
    "        tweet_relevante = self.tweet_relevante\n",
    "        tweet_irrelevante = self.tweet_irrelevante\n",
    "        lista = self.Ltreinamento\n",
    "        for tweet in lista:\n",
    "            if tweet[1] == 1:\n",
    "                tweet_relevante.append(tweet)\n",
    "            else:\n",
    "                tweet_irrelevante.append(tweet)\n",
    "            print(tweet)    \n",
    "            tweet[0] = tweet[0].split(' ')\n",
    "            for palavra in tweet[0]:\n",
    "                esta_na_lista = False\n",
    "                for freq_de_palavras in self.lista_freq_de_palavras:\n",
    "                    if freq_de_palavras[0] == palavra:\n",
    "                        esta_na_lista = True\n",
    "                        FR = freq_de_palavras[1]\n",
    "                        FIR = freq_de_palavras[2]\n",
    "                        if tweet in tweet_relevante:\n",
    "                            FR += 1\n",
    "                        else:\n",
    "                            FIR += 1\n",
    "                        freq_de_palavras[1] = FR\n",
    "                        freq_de_palavras[2] = FIR\n",
    "                        \n",
    "                    if not esta_na_lista:\n",
    "                        tipo_de_amostra\n",
    "                        if tweet in tweet_relevante:\n",
    "                            self.lista_freq_de_palavras.append([palavra,1,0])\n",
    "                        else:\n",
    "                            self.lista_freq_de_palavras.append([palavra,0,1])\n",
    "                            \n",
    "    def analise(self,tweet): \n",
    "        PA =  len(self.tweet_relevante)/(300) #variando de 0 a 1\n",
    "        PB =  len(self.tweet_irrelevante)/(300) #variando de 0 a 1\n",
    "        tweet = tweet.split(' ')\n",
    "        lista_Total = []\n",
    "        for palavra in tweet:\n",
    "            esta_na_lista = False\n",
    "            for freq_de_palavras in self.lista_freq_de_palavras:\n",
    "                if freq_de_palavras[0] == palavra:\n",
    "                    esta_na_lista = True\n",
    "                    Ph = (freq_de_palavras[1]+[2]+1)/self.tipo_de_amostra\n",
    "                    PhA = (freq_de_palavras[1]+1)/(self.tipo_de_amostra + self.quantidade_de_palavras[1])\n",
    "                    PhB = (freq_de_palavras[1]+1)/(self.tipo_de_amostra + self.quantidade_de_palavras[2])\n",
    "                    lista_h = []\n",
    "                    lista_PhA = []\n",
    "                    lista_PhB = []\n",
    "                    lista_h.append(Ph)\n",
    "                    lista_PhA.append(PhA)\n",
    "                    lista_PhB.append(PhB)\n",
    "                    lista_Total.append([Ph,PhB,PhA])\n",
    "            \n",
    "            if not esta_na_lista:\n",
    "                lista_h.append(1/tipo_de_amostra)\n",
    "                lista_PhA(1/self.tipo_de_amostra + self.quantidade_de_palavras[1])\n",
    "                lista_PhB(1/self.tipo_de_amostra + self.quantidade_de_palavras[2])\n",
    "        \n",
    "        PH = multiply(lista_h)\n",
    "        PHrel = multiply(lista_PhA)\n",
    "        PHirel = multiply(lista_PhB)\n",
    "        bayes_relevante = (PHrel * len(self.tweet_relevante))/PH\n",
    "        bayes_irrelevante = (PHirel * len(self.tweet_irrelevante))/PH\n",
    "        if (bayes_relevante>bayes_irrelevante): return 1\n",
    "        return 0\n",
    "        \n",
    "    def teste(self):\n",
    "        sim_acerto = 0\n",
    "        sim_erro = 0\n",
    "        nao_acerto = 0\n",
    "        nao_erro = 0\n",
    "        total_acerto = 0\n",
    "        total_erro = 0\n",
    "        for tweet in teste:\n",
    "            if analise(tweet[0] == tweet[1]):\n",
    "                total_acerto += 1\n",
    "                if tweet[0]:\n",
    "                    sim_acerto += 1\n",
    "                else:\n",
    "                    nao_acerto += 1\n",
    "            else:\n",
    "                total_erro += 1\n",
    "                if tweet[0]:\n",
    "                    sim_erro += 1\n",
    "                else:\n",
    "                    nao_erro += 1\n",
    "        print(\"total de erros:\" +str(total_erro))\n",
    "        print(\"total de acertos\" +str(nao_acerto))\n",
    "        print(\"positivo falso\" +str(sim_erro))\n",
    "        print(\"positivo verdadeiro\" +str(sim_acerto))\n",
    "        print(\"negativo falso\" +str(nao_erro))\n",
    "        print(\"negativo verdadeiro\" +str(nao_acerto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['may oq vc tem na sua mochila pra mim comer \\nnada\\n√© pra vc kit kat bolacha e fandango üòÇüòÇüòÇ', 0]\n",
      "['kit kat ja √© bom imagina o branco', 1]\n",
      "['rt @gustavosltt kit kat √© o mundo', 0]\n",
      "['t√° melhorando! ^ ^ v\\nfinalizei o √∫ltimo novamente! ^ ^ v\\n#teamvictory prit lohgann jefferson dos kit kat aleat‚Ä¶ https  t co hjnvdew127', 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-879cf05b556d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mClassifica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mClassifica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mClassifica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtreino\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mClassifica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-be60dbffe8ff>\u001b[0m in \u001b[0;36mtreino\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlista_freq_de_palavras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlista_freq_de_palavras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0manalise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Classifica = Classificador(Ltreinamento,Lteste)\n",
    "Classifica.normalize(0)\n",
    "Classifica.normalize(1)\n",
    "Classifica.treino()\n",
    "Classifica.teste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
